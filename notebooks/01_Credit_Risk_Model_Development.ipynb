{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Model Development\n",
    "\n",
    "This notebook demonstrates the end-to-end process of developing a credit risk model using the RiskModel framework. We'll cover:\n",
    "\n",
    "1. Generating synthetic credit data\n",
    "2. Preprocessing and feature engineering\n",
    "3. Model training and hyperparameter tuning\n",
    "4. Model evaluation\n",
    "\n",
    "This workflow follows industry best practices for developing credit risk models in a banking environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "# Add the parent directory to path to import local modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Import local modules\n",
    "from src.data_processing.generate_synthetic_data import generate_credit_data, split_and_save_data\n",
    "from src.data_processing.preprocess import preprocess_data, create_feature_pipeline\n",
    "from src.model_development.models import train_model, compare_models, CreditRiskModel\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Load configuration\n",
    "with open('../config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "For this demonstration, we'll generate synthetic credit data that mimics real-world loan applications and default patterns. In a real-world scenario, you would use historical customer data from your bank's systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic credit data\n",
    "print(\"Generating synthetic credit data...\")\n",
    "data = generate_credit_data(n_samples=10000, random_seed=42)\n",
    "\n",
    "# Display data sample\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data exploration\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"\\nDefault rate:\")\n",
    "print(data['default_flag'].value_counts(normalize=True))\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA - Numerical features distributions\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_cols = [col for col in numerical_cols if col != 'default_flag']\n",
    "\n",
    "# Plot distribution of numerical features\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_cols[:9]):\n",
    "    sns.histplot(data=data, x=col, hue='default_flag', kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic EDA - Categorical features\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "fig, axes = plt.subplots(len(categorical_cols), 1, figsize=(12, 4*len(categorical_cols)))\n",
    "if len(categorical_cols) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    # Create a cross-tabulation of the categorical feature vs default flag\n",
    "    ct = pd.crosstab(data[col], data['default_flag'], normalize='index')\n",
    "    ct.plot(kind='bar', stacked=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Default Rate by {col}')\n",
    "    axes[i].set_ylabel('Proportion')\n",
    "    axes[i].set_xlabel(col)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = data.select_dtypes(include=['float64', 'int64']).corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Numeric Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Now we'll preprocess the data using our framework's standardized techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, test, and validation sets\n",
    "target_variable = config['data']['target_variable']\n",
    "train_data, test_data, val_data = split_and_save_data(data, output_dir='../data', test_size=0.2, validation_size=0.1)\n",
    "\n",
    "# Display split sizes\n",
    "print(f\"Training data: {train_data.shape[0]} samples\")\n",
    "print(f\"Test data: {test_data.shape[0]} samples\")\n",
    "print(f\"Validation data: {val_data.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessing_pipeline = create_feature_pipeline(config, target_col=target_variable)\n",
    "\n",
    "# Preprocess training data\n",
    "X_train, y_train = preprocess_data(\n",
    "    train_data,\n",
    "    config,\n",
    "    target_col=target_variable,\n",
    "    is_training=True,\n",
    "    preprocessing_pipeline=preprocessing_pipeline\n",
    ")\n",
    "\n",
    "# Preprocess test data\n",
    "X_test, y_test = preprocess_data(\n",
    "    test_data,\n",
    "    config,\n",
    "    target_col=target_variable, \n",
    "    is_training=False, \n",
    "    preprocessing_pipeline=preprocessing_pipeline\n",
    ")\n",
    "\n",
    "# Preprocess validation data\n",
    "X_val, y_val = preprocess_data(\n",
    "    val_data,\n",
    "    config,\n",
    "    target_col=target_variable, \n",
    "    is_training=False, \n",
    "    preprocessing_pipeline=preprocessing_pipeline\n",
    ")\n",
    "\n",
    "# Display preprocessed feature sample\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Development\n",
    "\n",
    "Now we'll train and compare different model types to find the most suitable one for our credit risk assessment task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare multiple model types\n",
    "model_types = ['logistic_regression', 'random_forest', 'gradient_boosting']\n",
    "model_results = compare_models(X_train, y_train, X_test, y_test, model_types=model_types)\n",
    "\n",
    "# Display comparison results\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the best model with hyperparameter tuning\n",
    "best_model_type = model_results.iloc[model_results['roc_auc'].idxmax()]['model_type']\n",
    "print(f\"Best model type: {best_model_type}\")\n",
    "\n",
    "# Train the model with hyperparameter tuning\n",
    "tuned_model = train_model(X_train, y_train, model_type=best_model_type, tune=True)\n",
    "\n",
    "# Create model instance using our framework\n",
    "credit_model = CreditRiskModel(best_model_type, model=tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Let's evaluate our model's performance using various metrics and visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "test_metrics = credit_model.evaluate(X_test, y_test)\n",
    "print(\"Test set metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.gca()\n",
    "credit_model.plot_roc_curve(X_test, y_test, ax=ax)\n",
    "plt.title('ROC Curve on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = plt.gca()\n",
    "credit_model.plot_precision_recall_curve(X_test, y_test, ax=ax)\n",
    "plt.title('Precision-Recall Curve on Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "if hasattr(credit_model.model, 'feature_importances_') or best_model_type == 'logistic_regression':\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = plt.gca()\n",
    "    credit_model.plot_feature_importance(top_n=20, ax=ax)\n",
    "    plt.title('Top 20 Feature Importances')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save the Model\n",
    "\n",
    "Finally, we'll save our trained model for later use in validation and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for models if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "model_path = f'../models/credit_risk_{best_model_type}.pkl'\n",
    "credit_model.save_model(model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary\n",
    "\n",
    "In this notebook, we've demonstrated the process of developing a credit risk model following industry best practices:\n",
    "\n",
    "1. We generated and explored synthetic credit data\n",
    "2. We prepared the data using standardized preprocessing techniques\n",
    "3. We trained multiple model types and selected the best performer\n",
    "4. We evaluated the model using appropriate metrics for credit risk assessment\n",
    "5. We saved the model for future use\n",
    "\n",
    "In the next notebook, we'll cover the model validation process, including performance testing, stability assessment, and sensitivity analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}